apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: cluster
  region: eu-north-1
  tags:
    owner: platform
    environment: production

vpc:
  id: vpc-041fd1a6f86db3907
  cidr: 10.8.0.0/16
  subnets:
    private:
      # Max 2046 pods/hosts / AZ in this cluster
      eu-north-1a: { id: subnet-00544d341582321e9, cidr: 10.8.0.0/21 }
      eu-north-1b: { id: subnet-0b1c35e2317dd4acd, cidr: 10.8.8.0/21 }
      eu-north-1c: { id: subnet-059c0f88e61fae7bb, cidr: 10.8.16.0/21 }
    public:
      # Max 510 public resources / AZ on this cluster
      eu-north-1a: { id: subnet-052002bc830362604, cidr: 10.8.24.0/23 }
      eu-north-1b: { id: subnet-08bc9d4c0db7e580f, cidr: 10.8.26.0/23  }
      eu-north-1c: { id: subnet-008ce331e51e85839, cidr: 10.8.28.0/23  }     

nodeGroups:
  # Infra nodes, adds more instance policies
  - name: sap-eks-test-infra
    labels: 
      role: infra
      node-type.ohoy.io: infra
      node-role.kubernetes.io/infra: "true"
    instanceType: m5.large
    desiredCapacity: 3
    minSize: 2
    maxSize: 5
    kubeletExtraConfig:
        kubeReserved:
            cpu: "300m"
            memory: "1Gi"
            ephemeral-storage: "1Gi"
        kubeReservedCgroup: "/kube-reserved"
        systemReserved:
            cpu: "300m"
            memory: "300Mi"
            ephemeral-storage: "1Gi"
        evictionHard:
            memory.available:  "200Mi"
            nodefs.available: "10%"
        featureGates:
            DynamicKubeletConfig: true
            RotateKubeletServerCertificate: true # has to be enabled, otherwise it will be disabled
    privateNetworking: true
    volumeSize: 100
    volumeType: gp2
    volumeEncrypted: true
    preBootstrapCommands:
      - | 
        cat <<EOF > /etc/sysctl.d/10-disable-ipv6.conf
        # disable ipv6 config
        net.ipv6.conf.all.disable_ipv6 = 1
        net.ipv6.conf.default.disable_ipv6 = 1
        net.ipv6.conf.lo.disable_ipv6 = 1
        EOF
      - |
        cat <<EOF > /etc/sysctl.d/99-kube-net.conf
        # Have a larger connection range available
        net.ipv4.ip_local_port_range=1024 65000
        
        # Reuse closed sockets faster
        net.ipv4.tcp_tw_reuse=1
        net.ipv4.tcp_fin_timeout=15
        
        # The maximum number of "backlogged sockets".  Default is 128.
        net.core.somaxconn=4096
        net.core.netdev_max_backlog=4096
        
        # 16MB per socket - which sounds like a lot,
        # but will virtually never consume that much.
        net.core.rmem_max=16777216
        net.core.wmem_max=16777216
        
        # Various network tunables
        net.ipv4.tcp_max_syn_backlog=20480
        net.ipv4.tcp_max_tw_buckets=400000
        net.ipv4.tcp_no_metrics_save=1
        net.ipv4.tcp_rmem=4096 87380 16777216
        net.ipv4.tcp_syn_retries=2
        net.ipv4.tcp_synack_retries=2
        net.ipv4.tcp_wmem=4096 65536 16777216
        #vm.min_free_kbytes=65536
        
        # Connection tracking to prevent dropped connections (usually issue on LBs)
        net.netfilter.nf_conntrack_max=262144
        net.ipv4.netfilter.ip_conntrack_generic_timeout=120
        net.netfilter.nf_conntrack_tcp_timeout_established=86400
        
        # ARP cache settings for a highly loaded docker swarm
        net.ipv4.neigh.default.gc_thresh1=8096
        net.ipv4.neigh.default.gc_thresh2=12288
        net.ipv4.neigh.default.gc_thresh3=16384
        EOF
      - "systemctl restart systemd-sysctl.service"
    ssh:
      publicKeyName: platform
    iam:
      withAddonPolicies:
        imageBuilder: true
        autoScaler: true
        externalDNS: true
        certManager: true
        ebs: true
        albIngress: true
  # Standard workers.
  - name: sap-eks-test-workers
    labels: 
      role: workers
      node-type.ohoy.io: app
      node-role.kubernetes.io/worker: "true"
    instanceType: m5.large
    desiredCapacity: 3
    minSize: 2
    maxSize: 5
    kubeletExtraConfig:
        kubeReserved:
            cpu: "300m"
            memory: "1Gi"
            ephemeral-storage: "1Gi"
        kubeReservedCgroup: "/kube-reserved"
        systemReserved:
            cpu: "300m"
            memory: "300Mi"
            ephemeral-storage: "1Gi"
        evictionHard:
            memory.available:  "200Mi"
            nodefs.available: "10%"
        featureGates:
            DynamicKubeletConfig: true
            RotateKubeletServerCertificate: true # has to be enabled, otherwise it will be disabled
    privateNetworking: true
    volumeSize: 100
    volumeType: gp2
    volumeEncrypted: true
    preBootstrapCommands:
      - | 
        cat <<EOF > /etc/sysctl.d/10-disable-ipv6.conf
        # disable ipv6 config
        net.ipv6.conf.all.disable_ipv6 = 1
        net.ipv6.conf.default.disable_ipv6 = 1
        net.ipv6.conf.lo.disable_ipv6 = 1
        EOF
      - |
        cat <<EOF > /etc/sysctl.d/99-kube-net.conf
        # Have a larger connection range available
        net.ipv4.ip_local_port_range=1024 65000
        
        # Reuse closed sockets faster
        net.ipv4.tcp_tw_reuse=1
        net.ipv4.tcp_fin_timeout=15
        
        # The maximum number of "backlogged sockets".  Default is 128.
        net.core.somaxconn=4096
        net.core.netdev_max_backlog=4096
        
        # 16MB per socket - which sounds like a lot,
        # but will virtually never consume that much.
        net.core.rmem_max=16777216
        net.core.wmem_max=16777216
        
        # Various network tunables
        net.ipv4.tcp_max_syn_backlog=20480
        net.ipv4.tcp_max_tw_buckets=400000
        net.ipv4.tcp_no_metrics_save=1
        net.ipv4.tcp_rmem=4096 87380 16777216
        net.ipv4.tcp_syn_retries=2
        net.ipv4.tcp_synack_retries=2
        net.ipv4.tcp_wmem=4096 65536 16777216
        #vm.min_free_kbytes=65536
        
        # Connection tracking to prevent dropped connections (usually issue on LBs)
        net.netfilter.nf_conntrack_max=262144
        net.ipv4.netfilter.ip_conntrack_generic_timeout=120
        net.netfilter.nf_conntrack_tcp_timeout_established=86400
        
        # ARP cache settings for a highly loaded docker swarm
        net.ipv4.neigh.default.gc_thresh1=8096
        net.ipv4.neigh.default.gc_thresh2=12288
        net.ipv4.neigh.default.gc_thresh3=16384
        EOF
      - "systemctl restart systemd-sysctl.service"
    ssh:
      publicKeyName: platform
    iam:
      withAddonPolicies:
        ebs: true
        albIngress: true
  # spot node workers
  - name: sap-eks-test-spot-workers
    labels: 
      role: workers
      node-type.ohoy.io: spot
      node-role.kubernetes.io/worker: "true"
    taints:
      node-type: "spot:NoSchedule"
    desiredCapacity: 3
    minSize: 2
    maxSize: 5
    kubeletExtraConfig:
        kubeReserved:
            cpu: "300m"
            memory: "1Gi"
            ephemeral-storage: "1Gi"
        kubeReservedCgroup: "/kube-reserved"
        systemReserved:
            cpu: "300m"
            memory: "300Mi"
            ephemeral-storage: "1Gi"
        evictionHard:
            memory.available:  "200Mi"
            nodefs.available: "10%"
        featureGates:
            DynamicKubeletConfig: true
            RotateKubeletServerCertificate: true # has to be enabled, otherwise it will be disabled
    instancesDistribution:
      instanceTypes: ["m5.large", "m5.xlarge"]
    privateNetworking: true
    volumeSize: 100
    volumeType: gp2
    volumeEncrypted: true
    preBootstrapCommands:
      - | 
        cat <<EOF > /etc/sysctl.d/10-disable-ipv6.conf
        # disable ipv6 config
        net.ipv6.conf.all.disable_ipv6 = 1
        net.ipv6.conf.default.disable_ipv6 = 1
        net.ipv6.conf.lo.disable_ipv6 = 1
        EOF
      - |
        cat <<EOF > /etc/sysctl.d/99-kube-net.conf
        # Have a larger connection range available
        net.ipv4.ip_local_port_range=1024 65000
        
        # Reuse closed sockets faster
        net.ipv4.tcp_tw_reuse=1
        net.ipv4.tcp_fin_timeout=15
        
        # The maximum number of "backlogged sockets".  Default is 128.
        net.core.somaxconn=4096
        net.core.netdev_max_backlog=4096
        
        # 16MB per socket - which sounds like a lot,
        # but will virtually never consume that much.
        net.core.rmem_max=16777216
        net.core.wmem_max=16777216
        
        # Various network tunables
        net.ipv4.tcp_max_syn_backlog=20480
        net.ipv4.tcp_max_tw_buckets=400000
        net.ipv4.tcp_no_metrics_save=1
        net.ipv4.tcp_rmem=4096 87380 16777216
        net.ipv4.tcp_syn_retries=2
        net.ipv4.tcp_synack_retries=2
        net.ipv4.tcp_wmem=4096 65536 16777216
        #vm.min_free_kbytes=65536
        
        # Connection tracking to prevent dropped connections (usually issue on LBs)
        net.netfilter.nf_conntrack_max=262144
        net.ipv4.netfilter.ip_conntrack_generic_timeout=120
        net.netfilter.nf_conntrack_tcp_timeout_established=86400
        
        # ARP cache settings for a highly loaded docker swarm
        net.ipv4.neigh.default.gc_thresh1=8096
        net.ipv4.neigh.default.gc_thresh2=12288
        net.ipv4.neigh.default.gc_thresh3=16384
        EOF
      - "systemctl restart systemd-sysctl.service"
    ssh:
      publicKeyName: platform
    iam:
      withAddonPolicies:
        ebs: true
        albIngress: true